# =============================================================================
# TRM Platform - Chaos Engineering Tests
# Using Litmus Chaos Framework
# Following Netflix Chaos Engineering principles
# =============================================================================

# -----------------------------------------------------------------------------
# 1. Pod Delete Experiment
# Tests application resilience to pod failures
# -----------------------------------------------------------------------------
apiVersion: litmuschaos.io/v1alpha1
kind: ChaosEngine
metadata:
  name: trm-pod-delete
  namespace: litmus
spec:
  appinfo:
    appns: 'trm'
    applabel: 'app.kubernetes.io/name=trm'
    appkind: 'deployment'
  # Don't stop on failure - continue testing
  engineState: 'active'
  # Don't allow chaos during business hours
  auxiliaryAppInfo: ''
  annotationCheck: 'true'
  # Service account for chaos experiments
  serviceAccountName: litmus-admin
  # Define chaos experiments
  experiments:
    - name: pod-delete
      spec:
        components:
          env:
            # Total duration of chaos
            - name: TOTAL_CHAOS_DURATION
              value: '60'
            # Interval between pod deletes
            - name: CHAOS_INTERVAL
              value: '10'
            # Force delete (don't wait for graceful termination)
            - name: FORCE
              value: 'false'
            # Target pod name (empty = random)
            - name: PODS_AFFECTED_PERC
              value: '50'
            # Namespace of target pods
            - name: TARGET_CONTAINER
              value: ''
        # Probe to verify application health during chaos
        probe:
          - name: "health-check-probe"
            type: "httpProbe"
            mode: "Continuous"
            runProperties:
              probeTimeout: '5s'
              retry: 2
              interval: '5s'
              probePollingInterval: '2s'
              initialDelay: '2s'
            httpProbe/inputs:
              url: 'http://trm-app.trm.svc.cluster.local:3000/api/health'
              insecureSkipVerify: false
              method:
                get:
                  criteria: ==
                  responseCode: '200'

---
# -----------------------------------------------------------------------------
# 2. Network Latency Experiment
# Tests application behavior under network delays
# -----------------------------------------------------------------------------
apiVersion: litmuschaos.io/v1alpha1
kind: ChaosEngine
metadata:
  name: trm-network-latency
  namespace: litmus
spec:
  appinfo:
    appns: 'trm'
    applabel: 'app.kubernetes.io/name=trm'
    appkind: 'deployment'
  engineState: 'active'
  annotationCheck: 'true'
  serviceAccountName: litmus-admin
  experiments:
    - name: network-latency
      spec:
        components:
          env:
            # Network interface
            - name: NETWORK_INTERFACE
              value: 'eth0'
            # Target service ports
            - name: TARGET_SERVICE_PORT
              value: '3000'
            # Latency to add (ms)
            - name: NETWORK_LATENCY
              value: '2000'
            # Duration of chaos
            - name: TOTAL_CHAOS_DURATION
              value: '120'
            # Interval between chaos injections
            - name: CHAOS_INTERVAL
              value: '30'
        probe:
          - name: "api-latency-probe"
            type: "httpProbe"
            mode: "Continuous"
            runProperties:
              probeTimeout: '10s'
              retry: 3
              interval: '10s'
              probePollingInterval: '5s'
              initialDelay: '5s'
            httpProbe/inputs:
              url: 'http://trm-app.trm.svc.cluster.local:3000/api/jobs'
              insecureSkipVerify: false
              method:
                get:
                  criteria: ==
                  responseCode: '200'

---
# -----------------------------------------------------------------------------
# 3. CPU Hog Experiment
# Tests application behavior under CPU pressure
# -----------------------------------------------------------------------------
apiVersion: litmuschaos.io/v1alpha1
kind: ChaosEngine
metadata:
  name: trm-cpu-hog
  namespace: litmus
spec:
  appinfo:
    appns: 'trm'
    applabel: 'app.kubernetes.io/name=trm'
    appkind: 'deployment'
  engineState: 'active'
  annotationCheck: 'true'
  serviceAccountName: litmus-admin
  experiments:
    - name: pod-cpu-hog
      spec:
        components:
          env:
            # Number of CPU cores to consume
            - name: CPU_CORES
              value: '2'
            # Duration of chaos
            - name: TOTAL_CHAOS_DURATION
              value: '180'
            # Target container
            - name: TARGET_CONTAINER
              value: 'app'
            # Fill percentage
            - name: PODS_AFFECTED_PERC
              value: '30'
        probe:
          - name: "cpu-health-probe"
            type: "cmdProbe"
            mode: "Edge"
            runProperties:
              probeTimeout: '5s'
              retry: 2
              interval: '5s'
              initialDelay: '5s'
            cmdProbe/inputs:
              command: 'kubectl top pod -n trm -l app.kubernetes.io/name=trm --no-headers | awk \'{print $2}\''
              comparator:
                type: 'string'
                criteria: 'contains'
                value: 'm'

---
# -----------------------------------------------------------------------------
# 4. Memory Hog Experiment
# Tests application behavior under memory pressure
# -----------------------------------------------------------------------------
apiVersion: litmuschaos.io/v1alpha1
kind: ChaosEngine
metadata:
  name: trm-memory-hog
  namespace: litmus
spec:
  appinfo:
    appns: 'trm'
    applabel: 'app.kubernetes.io/name=trm'
    appkind: 'deployment'
  engineState: 'active'
  annotationCheck: 'true'
  serviceAccountName: litmus-admin
  experiments:
    - name: pod-memory-hog
      spec:
        components:
          env:
            # Amount of memory to consume (MB)
            - name: MEMORY_CONSUMPTION
              value: '500'
            # Duration of chaos
            - name: TOTAL_CHAOS_DURATION
              value: '180'
            # Target container
            - name: TARGET_CONTAINER
              value: 'app'
            # Fill percentage
            - name: PODS_AFFECTED_PERC
              value: '30'
        probe:
          - name: "memory-health-probe"
            type: "httpProbe"
            mode: "Continuous"
            runProperties:
              probeTimeout: '10s'
              retry: 3
              interval: '15s'
              probePollingInterval: '5s'
              initialDelay: '10s'
            httpProbe/inputs:
              url: 'http://trm-app.trm.svc.cluster.local:3000/api/health/deep'
              insecureSkipVerify: false
              method:
                get:
                  criteria: ==
                  responseCode: '200'

---
# -----------------------------------------------------------------------------
# 5. Database Failure Experiment
# Tests application resilience to database failures
# -----------------------------------------------------------------------------
apiVersion: litmuschaos.io/v1alpha1
kind: ChaosEngine
metadata:
  name: trm-mongodb-failure
  namespace: litmus
spec:
  appinfo:
    appns: 'trm'
    applabel: 'app.kubernetes.io/component=database'
    appkind: 'statefulset'
  engineState: 'active'
  annotationCheck: 'true'
  serviceAccountName: litmus-admin
  experiments:
    - name: pod-delete
      spec:
        components:
          env:
            - name: TOTAL_CHAOS_DURATION
              value: '300'
            - name: CHAOS_INTERVAL
              value: '60'
            - name: FORCE
              value: 'false'
            - name: PODS_AFFECTED_PERC
              value: '33'  # Delete one pod in 3-node replica set
        probe:
          - name: "db-resilience-probe"
            type: "httpProbe"
            mode: "Continuous"
            runProperties:
              probeTimeout: '10s'
              retry: 5
              interval: '10s'
              probePollingInterval: '5s'
              initialDelay: '10s'
              stopOnFailure: false
            httpProbe/inputs:
              url: 'http://trm-app.trm.svc.cluster.local:3000/api/jobs?page=1&limit=10'
              insecureSkipVerify: false
              method:
                get:
                  criteria: 'oneOf'
                  responseCode: '200,503'

---
# -----------------------------------------------------------------------------
# 6. Chaos Schedule - Run experiments regularly
# -----------------------------------------------------------------------------
apiVersion: litmuschaos.io/v1alpha1
kind: ChaosSchedule
metadata:
  name: trm-weekly-chaos
  namespace: litmus
spec:
  schedule:
    type: "repeat"
    startTime: "2024-02-10T02:00:00Z"
    endTime: "2024-12-31T23:59:59Z"
    minChaosInterval: 
      hour:
        interval: 168  # Run weekly
  engineTemplateSpec:
    appinfo:
      appns: 'trm'
      applabel: 'app.kubernetes.io/name=trm'
      appkind: 'deployment'
    engineState: 'active'
    annotationCheck: 'true'
    serviceAccountName: litmus-admin
    experiments:
      - name: pod-delete
        spec:
          components:
            env:
              - name: TOTAL_CHAOS_DURATION
                value: '60'
              - name: CHAOS_INTERVAL
                value: '10'
              - name: FORCE
                value: 'false'
              - name: PODS_AFFECTED_PERC
                value: '25'

---
# -----------------------------------------------------------------------------
# Installation Instructions:
# -----------------------------------------------------------------------------
# 1. Install Litmus Chaos:
#    kubectl apply -f https://litmuschaos.github.io/litmus/litmus-operator-v3.0.0.yaml
#
# 2. Install Chaos experiments:
#    kubectl apply -f https://hub.litmuschaos.io/api/chaos/3.0.0?file=charts/generic/pod-delete/experiment.yaml
#    kubectl apply -f https://hub.litmuschaos.io/api/chaos/3.0.0?file=charts/generic/network-latency/experiment.yaml
#    kubectl apply -f https://hub.litmuschaos.io/api/chaos/3.0.0?file=charts/generic/pod-cpu-hog/experiment.yaml
#    kubectl apply -f https://hub.litmuschaos.io/api/chaos/3.0.0?file=charts/generic/pod-memory-hog/experiment.yaml
#
# 3. Create service account:
#    kubectl create serviceaccount litmus-admin -n litmus
#    kubectl create clusterrolebinding litmus-admin --clusterrole=cluster-admin --serviceaccount=litmus:litmus-admin
#
# 4. Apply chaos tests:
#    kubectl apply -f tests/chaos/
#
# 5. Monitor chaos experiments:
#    kubectl get chaosengine -n litmus
#    kubectl describe chaosengine trm-pod-delete -n litmus
#
# 6. View chaos results:
#    kubectl get chaosresult -n litmus
# -----------------------------------------------------------------------------
